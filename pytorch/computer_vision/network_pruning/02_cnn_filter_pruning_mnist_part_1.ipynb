{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV - CNN Filter Pruning - MNIST - Part 1\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you through the implementation of filter pruning of CNNs using the MNIST dataset on PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0ad1c97db0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train = datasets.MNIST('../../../data/computer_vision/mnist', train=True, download=True, transform=data_transform)\n",
    "\n",
    "test = datasets.MNIST('../../../data/computer_vision/mnist', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input-output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images (batch, channels, height, width):  torch.Size([64, 1, 28, 28])\n",
      "Output labels:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "print(\"Input images (batch, channels, height, width): \", images.size())\n",
    "print(\"Output labels: \", labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example image from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0a7e2d0c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CNN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MnistClassifier, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(1, 4, kernel_size=3, stride=1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(13*13*4, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv(x))\n",
    "        out = self.maxpool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skip the following part and directly load a saved model given a few cells below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CNN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 7\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = MnistClassifier()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        loss = criterion(y_pred_probs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        batch_acc = (y_pred == y_batch).sum().item()/BATCH_SIZE\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist_big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model (on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = MnistClassifier()\n",
    "model.load_state_dict(torch.load(\"mnist_big\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Device: \", device)\n",
    "params_before_pruning = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.82 s ± 55.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      7840\n",
      "           1       0.98      0.97      0.97      9080\n",
      "           2       0.95      0.93      0.94      8256\n",
      "           3       0.97      0.93      0.95      8080\n",
      "           4       0.94      0.97      0.96      7856\n",
      "           5       0.94      0.94      0.94      7136\n",
      "           6       0.98      0.97      0.97      7664\n",
      "           7       0.94      0.92      0.93      8224\n",
      "           8       0.84      0.95      0.89      7792\n",
      "           9       0.96      0.91      0.94      8072\n",
      "\n",
      "    accuracy                           0.95     80000\n",
      "   macro avg       0.95      0.95      0.95     80000\n",
      "weighted avg       0.95      0.95      0.95     80000\n",
      "\n",
      "\n",
      "Parameters before pruning:  6810\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))\n",
    "print(\"\\nParameters before pruning: \", params_before_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a filter with lowest L1 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight :  torch.Size([4, 1, 3, 3]) \n",
      " tensor([[[[ 3.3874e-02,  1.2109e-01,  5.0049e-01],\n",
      "          [-1.5165e-01, -4.3195e-02,  1.3526e-02],\n",
      "          [-4.5370e-01, -9.9016e-01, -3.3812e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4854e-03,  4.1072e-01, -1.7655e-01],\n",
      "          [-4.2791e-01,  6.6795e-01, -2.0674e-01],\n",
      "          [ 3.3002e-01,  1.6327e-01,  7.4090e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6852e-01, -2.8468e-01, -6.6331e+00],\n",
      "          [-3.1287e-01, -1.1904e-01, -6.5325e+00],\n",
      "          [-2.7918e-01, -2.2543e-01, -2.4872e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3184e-01, -6.8228e+00, -3.1576e+00],\n",
      "          [-6.7073e-01, -2.5972e-01, -1.6205e-02],\n",
      "          [-1.1910e-01,  4.7707e-01,  2.3824e-01]]]]) \n",
      "\n",
      "====================================================================================================\n",
      "tensor(1.2617)\n",
      "tensor(1.0064)\n",
      "tensor(9.3318)\n",
      "tensor(7.5757)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name == \"conv.weight\":\n",
    "            print (name, \": \",  param.shape, \"\\n\", param.data, \"\\n\")\n",
    "            print(\"=\" * 100)\n",
    "            for wt in param.data:\n",
    "                print(torch.norm(wt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the filter with lowest L1 norm 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      " conv.weight :  torch.Size([4, 1, 3, 3]) \n",
      " tensor([[[[ 3.3874e-02,  1.2109e-01,  5.0049e-01],\n",
      "          [-1.5165e-01, -4.3195e-02,  1.3526e-02],\n",
      "          [-4.5370e-01, -9.9016e-01, -3.3812e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4854e-03,  4.1072e-01, -1.7655e-01],\n",
      "          [-4.2791e-01,  6.6795e-01, -2.0674e-01],\n",
      "          [ 3.3002e-01,  1.6327e-01,  7.4090e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6852e-01, -2.8468e-01, -6.6331e+00],\n",
      "          [-3.1287e-01, -1.1904e-01, -6.5325e+00],\n",
      "          [-2.7918e-01, -2.2543e-01, -2.4872e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3184e-01, -6.8228e+00, -3.1576e+00],\n",
      "          [-6.7073e-01, -2.5972e-01, -1.6205e-02],\n",
      "          [-1.1910e-01,  4.7707e-01,  2.3824e-01]]]]) \n",
      "\n",
      "====================================================================================================\n",
      "Filter norm list:  [tensor(1.2617), tensor(1.0064), tensor(9.3318), tensor(7.5757)]\n",
      "\n",
      "Index of filter with smallest L1 norm:  1\n",
      "====================================================================================================\n",
      "After \n",
      " conv.weight :  torch.Size([4, 1, 3, 3]) \n",
      " tensor([[[[ 0.0339,  0.1211,  0.5005],\n",
      "          [-0.1517, -0.0432,  0.0135],\n",
      "          [-0.4537, -0.9902, -0.3381]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1685, -0.2847, -6.6331],\n",
      "          [-0.3129, -0.1190, -6.5325],\n",
      "          [-0.2792, -0.2254, -0.2487]]],\n",
      "\n",
      "\n",
      "        [[[-0.2318, -6.8228, -3.1576],\n",
      "          [-0.6707, -0.2597, -0.0162],\n",
      "          [-0.1191,  0.4771,  0.2382]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_norm_list = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name == \"conv.weight\":\n",
    "            print (\"Before \\n\", name, \": \",  param.shape, \"\\n\", param.data, \"\\n\")\n",
    "            print(\"=\" * 100)\n",
    "            for wt in param.data:\n",
    "                filter_norm_list.append(torch.norm(wt))\n",
    "            \n",
    "print(\"Filter norm list: \", filter_norm_list)\n",
    "                \n",
    "smallest_norm_filter_index = filter_norm_list.index(min(filter_norm_list))\n",
    "print(\"\\nIndex of filter with smallest L1 norm: \", smallest_norm_filter_index)\n",
    "\n",
    "model.conv.weight.data[smallest_norm_filter_index] = 0\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name == \"conv.weight\":\n",
    "            print(\"After \\n\", name, \": \",  param.shape, \"\\n\", param.data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test after making a filter 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77       980\n",
      "           1       0.92      0.96      0.94      1135\n",
      "           2       0.81      0.93      0.87      1032\n",
      "           3       0.90      0.80      0.85      1010\n",
      "           4       0.97      0.88      0.92       982\n",
      "           5       0.67      0.87      0.76       892\n",
      "           6       0.95      0.93      0.94       958\n",
      "           7       0.94      0.87      0.91      1028\n",
      "           8       0.72      0.80      0.76       974\n",
      "           9       0.90      0.90      0.90      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Parameters before pruning:  6810\n",
      "CPU times: user 20.4 s, sys: 240 ms, total: 20.6 s\n",
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))\n",
    "print(\"\\nParameters before pruning: \", params_before_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the filter with all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv.weight.data = model.conv.weight.data[1:]\n",
    "model.conv.bias.data = model.conv.bias.data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight :  torch.Size([3, 1, 3, 3]) \n",
      " tensor([[[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1685, -0.2847, -6.6331],\n",
      "          [-0.3129, -0.1190, -6.5325],\n",
      "          [-0.2792, -0.2254, -0.2487]]],\n",
      "\n",
      "\n",
      "        [[[-0.2318, -6.8228, -3.1576],\n",
      "          [-0.6707, -0.2597, -0.0162],\n",
      "          [-0.1191,  0.4771,  0.2382]]]]) \n",
      "\n",
      "conv.bias :  torch.Size([3]) \n",
      " tensor([-0.7288, -6.8801, -0.1915]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name == \"conv.weight\" or name == \"conv.bias\":\n",
    "            print (name, \": \",  param.shape, \"\\n\", param.data, \"\\n\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv = nn.Conv2d(1, 3, kernel_size=3, stride=1)\n",
    "model.fc = nn.Linear(13*13*3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Device: \", device)\n",
    "params_after_pruning = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy of changed architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 s ± 180 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.70      0.23      7840\n",
      "           1       0.00      0.00      0.00      9080\n",
      "           2       0.00      0.00      0.00      8256\n",
      "           3       0.01      0.01      0.01      8080\n",
      "           4       0.17      0.04      0.06      7856\n",
      "           5       0.09      0.40      0.15      7136\n",
      "           6       0.00      0.00      0.00      7664\n",
      "           7       0.36      0.00      0.01      8224\n",
      "           8       0.00      0.00      0.00      7792\n",
      "           9       0.00      0.00      0.00      8072\n",
      "\n",
      "    accuracy                           0.11     80000\n",
      "   macro avg       0.08      0.11      0.05     80000\n",
      "weighted avg       0.08      0.11      0.04     80000\n",
      "\n",
      "Parameters after pruning:  5110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshaj/miniconda3/envs/toothless/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))\n",
    "print(\"Parameters after pruning: \", params_after_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "MnistClassifier(\n",
      "  (conv): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (fc): Linear(in_features=507, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: | Loss: 0.32278 | Acc: 0.90705\n",
      "Epoch 01: | Loss: 0.20767 | Acc: 0.94085\n",
      "Epoch 02: | Loss: 0.19505 | Acc: 0.94744\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        loss = criterion(y_pred_probs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        batch_acc = (y_pred == y_batch).sum().item()/BATCH_SIZE\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy of pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 s ± 162 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      7840\n",
      "           1       0.96      0.97      0.97      9080\n",
      "           2       0.96      0.94      0.95      8256\n",
      "           3       0.95      0.96      0.96      8080\n",
      "           4       0.95      0.95      0.95      7856\n",
      "           5       0.97      0.92      0.94      7136\n",
      "           6       0.97      0.97      0.97      7664\n",
      "           7       0.94      0.95      0.94      8224\n",
      "           8       0.91      0.95      0.93      7792\n",
      "           9       0.94      0.92      0.93      8072\n",
      "\n",
      "    accuracy                           0.95     80000\n",
      "   macro avg       0.95      0.95      0.95     80000\n",
      "weighted avg       0.95      0.95      0.95     80000\n",
      "\n",
      "Parameters after pruning:  5110\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))\n",
    "print(\"Parameters after pruning: \", params_after_pruning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
